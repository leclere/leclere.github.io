---
title: "Stochastic Optimization"
collection: teaching
type: "Graduate course"
permalink: /teaching/OS
venue: "IPP, M2"
date: 2022-01-01
location: "ENSTA, France"
lesson: 1
---

This is a master level course about stochastic optimization.

The course is in two part: stochastic gradient and stochastic programming.

## Stochastic gradient and extensions (by O.Fercoq)

[courses notes](courses/Saclay/fercoq/poly_optsto_fercoq.pdf)
[exercises](courses/Saclay/fercoq/td_backpropagation.pdf)
[practical work](courses/Saclay/fercoq/TP_MNIST_basic_functions.ipynb)

- Introduction
- Stochastic gradient
- Stochastic variance reduced gradient
- Adaptative step-sizes
- Coordinate descent

## Stochastic and Dynamic programming (by V. Lecl√®re)

[Printable Handout](courses/Saclay/Saclay-handout.pdf)


### Practical work

[github link](https://github.com/leclere/TP-Saclay)

### 1. Convex optimization tools for stochastic optimization

[slides](courses/Saclay/Saclay-1.pdf)

### 2. Probability tools for stochastic optimization

[slides](courses/Saclay/Saclay-2.pdf)

### 3. Stochastic programming

[slides](courses/Saclay/Saclay-3.pdf)

### 4. Dynamic Programming and Bellman's Operators

[slides](courses/Saclay/Saclay-4.pdf)

### 5. Numerical methods for two-stage programming

[slides](courses/Saclay/Saclay-5.pdf)

### 6. Stochastic Dual Dynamic Programming

[slides](courses/Saclay/Saclay-6.pdf)

### Past exam

- [2018](courses/Saclay/2018-exam-OS.pdf) [answers](courses/Saclay/2018-exam-answers-OS.pdf)
- [2019](courses/Saclay/2019-exam-OS.pdf) [answers](courses/Saclay/2019-exam-answers-OS.pdf)

### References

- [Lectures on Stochastic Programming, Shapiro, Dentcheva, Ruszczynski](https://www2.isye.gatech.edu/people/faculty/Alex_Shapiro/SPbook.pdf)
- [Variational Analysis, Rockafellar, Wets](https://sites.math.washington.edu/~rtr/papers/rtr169-VarAnalysis-RockWets.pdf)
- [Convex Analysis](http://www.convexoptimization.com/TOOLS/ConvexAnalysisRockafellar.pdf)